{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81aee32-8447-4e21-a0f2-248586b9bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()\n",
    "PROJECT_NAME = 'Desc-Title'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84776cf-8f38-4f69-b01e-c70a1cfd8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fef94cc-759d-4e9e-9154-423c5f1390af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$', '100']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('$100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aeeef38-c281-47d3-9a9b-96d82b7faf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e1c234-165c-4b3f-b5a8-3dfdf4094f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem('organic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac54e23a-3e09-4685-965f-981bc8e3636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(words))\n",
    "    for idx,w in enumerate(words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4b586cb-d884-4e66-87e2-702dad80e7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(['hi'],['hi','how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f422808a-e263-49f8-ad8d-eb3682a689ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a673379-f5a8-4432-ba70-38ef43bdc33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Daniel Simmons</td>\n",
       "      <td>3.4K</td>\n",
       "      <td>8</td>\n",
       "      <td>https://itnext.io/you-can-build-a-neural-netwo...</td>\n",
       "      <td>You can build a neural network in JavaScript e...</td>\n",
       "      <td>Click here to share this article on LinkedIn »...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Eugenio Culurciello</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/artificial-inte...</td>\n",
       "      <td>Artificial Intelligence, AI in 2018 and beyond...</td>\n",
       "      <td>These are my opinions on where deep neural net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Devin Soni</td>\n",
       "      <td>5.8K</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/spiking-neural-...</td>\n",
       "      <td>Spiking Neural Networks, the Next Generation o...</td>\n",
       "      <td>Everyone who has been remotely tuned in to rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Carlos E. Perez</td>\n",
       "      <td>3.9K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/intuitionmachine/neurons-ar...</td>\n",
       "      <td>Surprise! Neurons are Now More Complex than We...</td>\n",
       "      <td>One of the biggest misconceptions around is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Nityesh Agarwal</td>\n",
       "      <td>2.4K</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/wth-does-a-neur...</td>\n",
       "      <td>“WTH does a neural network even learn??” — a n...</td>\n",
       "      <td>I believe, we all have that psychologist/philo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author claps  reading_time  \\\n",
       "0             Justin Lee  8.3K            11   \n",
       "1            Conor Dewey  1.4K             7   \n",
       "2       William Koehrsen  2.8K            11   \n",
       "3           Gant Laborde  1.3K             7   \n",
       "4       Emmanuel Ameisen   935            11   \n",
       "..                   ...   ...           ...   \n",
       "332       Daniel Simmons  3.4K             8   \n",
       "333  Eugenio Culurciello  2.8K            13   \n",
       "334           Devin Soni  5.8K             4   \n",
       "335      Carlos E. Perez  3.9K             7   \n",
       "336      Nityesh Agarwal  2.4K            13   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1    https://towardsdatascience.com/python-for-data...   \n",
       "2    https://towardsdatascience.com/automated-featu...   \n",
       "3    https://medium.freecodecamp.org/machine-learni...   \n",
       "4    https://blog.insightdatascience.com/reinforcem...   \n",
       "..                                                 ...   \n",
       "332  https://itnext.io/you-can-build-a-neural-netwo...   \n",
       "333  https://towardsdatascience.com/artificial-inte...   \n",
       "334  https://towardsdatascience.com/spiking-neural-...   \n",
       "335  https://medium.com/intuitionmachine/neurons-ar...   \n",
       "336  https://towardsdatascience.com/wth-does-a-neur...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Chatbots were the next big thing: what happene...   \n",
       "1    Python for Data Science: 8 Concepts You May Ha...   \n",
       "2    Automated Feature Engineering in Python – Towa...   \n",
       "3    Machine Learning: how to go from Zero to Hero ...   \n",
       "4    Reinforcement Learning from scratch – Insight ...   \n",
       "..                                                 ...   \n",
       "332  You can build a neural network in JavaScript e...   \n",
       "333  Artificial Intelligence, AI in 2018 and beyond...   \n",
       "334  Spiking Neural Networks, the Next Generation o...   \n",
       "335  Surprise! Neurons are Now More Complex than We...   \n",
       "336  “WTH does a neural network even learn??” — a n...   \n",
       "\n",
       "                                                  text  \n",
       "0    Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1    If you’ve ever found yourself looking up the s...  \n",
       "2    Machine learning is increasingly moving from h...  \n",
       "3    If your understanding of A.I. and Machine Lear...  \n",
       "4    Want to learn about applied Artificial Intelli...  \n",
       "..                                                 ...  \n",
       "332  Click here to share this article on LinkedIn »...  \n",
       "333  These are my opinions on where deep neural net...  \n",
       "334  Everyone who has been remotely tuned in to rec...  \n",
       "335  One of the biggest misconceptions around is th...  \n",
       "336  I believe, we all have that psychologist/philo...  \n",
       "\n",
       "[337 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da970701-fc69-4dc0-9e34-26e8fabce06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['title']\n",
    "X_words = []\n",
    "y_words = []\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee3a0ce-91b3-4756-90ab-15754cff0939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [00:10, 31.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    y_batch = tokenize(y_batch)\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    for yb in y_batch:\n",
    "        new_y.append(stem(yb))\n",
    "    data.append([new_X,new_y])\n",
    "    X_words.extend(new_X)\n",
    "    y_words.extend(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1f84728-fe19-4b0a-a0c2-8a6261cfd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b7e1e22-d7a6-4305-aa2a-8e8a5730fa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 337/337 [24:29<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "for desc,title in tqdm(data):\n",
    "    X.append(bag_of_words(desc,X_words))\n",
    "    y.append(bag_of_words(title,y_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1a8686e-11eb-4ec4-900a-d8f130bfab78",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_381857/1389262985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.125,shuffle=False)\n",
    "X_train = torch.from_numpy(np.array(X_train)).to(device).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).to(device).float()\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e39a67f-bb1c-4c64-a6bf-dc19f9952d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d39195d-e41f-4e39-a52b-0a716a97fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.iters = 10\n",
    "        self.activation = ReLU()\n",
    "        self.linear1 = Linear(len(X_words),512)\n",
    "        self.linear2 = Linear(512,512)\n",
    "        self.linear2bn = BatchNorm1d(512)\n",
    "        self.output = Linear(512,len(y_words))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.linear1(X)\n",
    "        for _ in range(self.iters):\n",
    "            preds = self.activation(self.linear2bn(self.linear2(preds)))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b72e1cba-13d0-44b6-8ba9-d2301618acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bec6b9-defe-4a0a-bb06-5a52a6062730",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model.pt')\n",
    "torch.save(model,'model.pth')\n",
    "torch.save(model.state_dict(),'model-sd.pt')\n",
    "torch.save(model.state_dict(),'model-sd.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d79c8-fc54-4461-8944-c8d0396d6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion)/2)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    model.train()\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff319761-8805-44db-bb3b-545cea956c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model,'model.pt')\n",
    "# torch.save(model,'model.pth')\n",
    "# torch.save(model.state_dict(),'model-sd.pt')\n",
    "# torch.save(model.state_dict(),'model-sd.pth')\n",
    "torch.save(X_words,'X_words.pt')\n",
    "torch.save(y_words,'y_words.pth')\n",
    "torch.save(data,'data.pt')\n",
    "torch.save(data,'data.pth')\n",
    "# torch.save(labels,'labels.pt')\n",
    "# torch.save(labels,'labels.pth')\n",
    "# torch.save(idx,'idx.pt')\n",
    "# torch.save(idx,'idx.pth')\n",
    "torch.save(y_train,'y_train.pt')\n",
    "torch.save(y_test,'y_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cba21-2f0a-4834-a413-fecd40d24ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
